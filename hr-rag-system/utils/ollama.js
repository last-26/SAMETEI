const axios = require('axios');
const natural = require('natural');
const config = require('../config');

class OllamaClient {
  constructor() {
    this.baseURL = config.ollama.baseURL;
    this.model = config.ollama.model;
    this.embeddingModel = config.ollama.embeddingModel;
    
    this.client = axios.create({
      baseURL: this.baseURL,
      timeout: 0, // Timeout kaldÄ±rÄ±ldÄ± - GPU'da model yÃ¼klenmesi uzun sÃ¼rebilir
      headers: {
        'Content-Type': 'application/json'
      }
    });
  }

  /**
   * Local TF-IDF embedding kullanarak metin vektÃ¶rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼r
   */
  async createEmbedding(text) {
    try {
      if (!text || text.trim().length === 0) {
        throw new Error('Metin boÅŸ olamaz');
      }

      // Metni kÃ¼Ã§Ã¼k harfe Ã§evir ve temizle
      const cleanText = text.toLowerCase()
        .replace(/[^\w\sÃ¼Ã§Ã¶ÄŸÄ±a-z]/gi, ' ') // TÃ¼rkÃ§e karakterleri koru
        .replace(/\s+/g, ' ')
        .trim();

      // Natural kÃ¼tÃ¼phanesi ile tokenize et
      const tokenizer = new natural.WordTokenizer();
      const tokens = tokenizer.tokenize(cleanText);
      
      if (!tokens || tokens.length === 0) {
        console.warn('âš ï¸ No tokens extracted from text, creating default embedding');
        // Return standard length vector for consistency
        return new Array(100).fill(0.01);
      }

      // TF-IDF vektÃ¶rÃ¼ oluÅŸtur (basit implementasyon)
      const vocabulary = [...new Set(tokens)]; // Benzersiz kelimeler
      
      // Ensure minimum vector length for consistency
      const minVectorLength = 100;
      const vectorLength = Math.max(vocabulary.length, minVectorLength);
      const vector = new Array(vectorLength).fill(0);
      
      // Her kelimenin frekansÄ±nÄ± hesapla
      const termFreq = {};
      tokens.forEach(token => {
        termFreq[token] = (termFreq[token] || 0) + 1;
      });

      // VektÃ¶rÃ¼ doldur
      vocabulary.forEach((word, index) => {
        if (index < vector.length) {
          const tf = termFreq[word] || 0;
          const normalizedTf = tf / tokens.length; // Normalize et
          vector[index] = normalizedTf;
        }
      });

      console.log(`ğŸ” Created embedding: length=${vector.length}, type=${typeof vector}, isArray=${Array.isArray(vector)}`);
      
      // Return only the vector array, not wrapped in an object
      return vector;
    } catch (error) {
      console.error('âŒ Embedding oluÅŸturma hatasÄ±:', error);
      // Return consistent fallback embedding
      return new Array(100).fill(0.01);
    }
  }

  /**
   * Birden fazla metin iÃ§in embedding oluÅŸtur
   */
  async createEmbeddings(texts) {
    console.log(`ğŸ“Š ${texts.length} metin iÃ§in embedding oluÅŸturuluyor...`);
    const embeddings = [];
    
    for (let i = 0; i < texts.length; i++) {
      try {
        const embeddingVector = await this.createEmbedding(texts[i]);
        
        // Validate the embedding is an array
        if (!Array.isArray(embeddingVector)) {
          console.warn(`âš ï¸ Embedding ${i+1} is not an array, converting...`);
          embeddings.push(new Array(100).fill(0.01));
        } else {
          embeddings.push(embeddingVector);
        }
        
        if ((i + 1) % 10 === 0) {
          console.log(`âœ… ${i + 1}/${texts.length} embedding oluÅŸturuldu`);
        }
      } catch (error) {
        console.error(`âŒ ${i + 1}. metin iÃ§in embedding oluÅŸturulamadÄ±:`, error.message);
        // Hata durumunda consistent fallback vektÃ¶r ekle
        embeddings.push(new Array(100).fill(0.01));
      }
    }

    console.log(`âœ… Toplam ${embeddings.length} embedding oluÅŸturuldu`);
    console.log(`ğŸ” First embedding check: type=${typeof embeddings[0]}, isArray=${Array.isArray(embeddings[0])}, length=${embeddings[0]?.length}`);
    return embeddings;
  }

  /**
   * Ollama ile chat completion
   */
  async createChatCompletion(messages, temperature = 0.3) {
    const retryCfg = config.ollama.retry;
    let attempt = 0;
    let delay = retryCfg.initialDelayMs;

    while (attempt <= retryCfg.maxRetries) {
      try {
        // Ollama API formatÄ±na Ã§evir
        const prompt = this.formatMessagesForOllama(messages);
        
        const response = await this.client.post('/api/generate', {
          model: this.model,
          prompt: prompt,
          stream: false,
          options: {
            temperature: temperature,
            num_predict: 1000, // Daha kÄ±sa response (loop'u Ã¶nlemek iÃ§in)
            repeat_penalty: 1.2, // TekrarlarÄ± cezalandÄ±r
            repeat_last_n: 64, // Son 64 token'Ä± kontrol et
            top_p: 0.9, // Daha fokuslu yanÄ±tlar
            stop: ["[TABLO]", "|", "```", "---"] // Stop tokens ekle
          }
        });

        if (response.data && response.data.response) {
          return response.data.response;
        }
        throw new Error('Ollama response format is invalid');
      } catch (error) {
        attempt++;
        console.error(`âŒ Ollama API hatasÄ± (Deneme ${attempt}/${retryCfg.maxRetries + 1}):`, error.message);
        
        if (attempt > retryCfg.maxRetries) {
          throw new Error(`Ollama baÄŸlantÄ±sÄ± baÅŸarÄ±sÄ±z. LÃ¼tfen Ollama servisinin Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan ve modelinizin yÃ¼klendiÄŸinden emin olun: ${error.message}`);
        }
        
        await new Promise(r => setTimeout(r, delay));
        delay *= retryCfg.backoffFactor;
      }
    }
  }

  /**
   * Messages'larÄ± Ollama prompt formatÄ±na Ã§evir
   */
  formatMessagesForOllama(messages) {
    let prompt = '';
    
    for (const message of messages) {
      if (message.role === 'system') {
        prompt += `System: ${message.content}\n\n`;
      } else if (message.role === 'user') {
        prompt += `User: ${message.content}\n\n`;
      } else if (message.role === 'assistant') {
        prompt += `Assistant: ${message.content}\n\n`;
      }
    }
    
    prompt += 'Assistant:';
    return prompt;
  }

  /**
   * HR AsistanÄ± iÃ§in Ã¶zelleÅŸtirilmiÅŸ chat completion
   */
  async hrChatCompletion(userQuery, context = '') {
    const fallback = `${require('../config').support.fallbackMessage}`;
    const systemPrompt = `Sen bir HR (Ä°nsan KaynaklarÄ±) asistanÄ±sÄ±n.

GÃ¶revin:
- Ã‡alÄ±ÅŸanlarÄ±n HR sorularÄ±nÄ± yanÄ±tlamak
- Her zaman nazik, yardÄ±mcÄ± ve profesyonel olmak
- Sadece aÅŸaÄŸÄ±daki ÅŸirket bilgilerini kullanarak cevap vermek

Ã–NEMLÄ°: EÄŸer sorulan konu aÅŸaÄŸÄ±daki bilgilerde yoksa, lÃ¼tfen ÅŸu mesajÄ± ver: "${fallback}".

ÅÄ°RKET BÄ°LGÄ°LERÄ°:
${context}

LÃ¼tfen kÄ±sa, Ã¶z ve anlaÅŸÄ±lÄ±r cevaplar ver. TÃ¼rkÃ§e yanÄ±t ver.`;

    const messages = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userQuery }
    ];

    return await this.createChatCompletion(messages, 0.2);
  }

  /**
   * Chat history ile Ã¼retken HR yanÄ±tÄ±
   */
  async hrChatCompletionWithHistory(userQuery, context = '', chatHistory = []) {
    const fallback = `${require('../config').support.fallbackMessage}`;
    
    const systemPrompt = `Sen yaratÄ±cÄ± ve akÄ±llÄ± bir HR (Ä°nsan KaynaklarÄ±) asistanÄ±sÄ±n.
    
GÃ¶revlerin:
- Ã‡alÄ±ÅŸanlarÄ±n HR sorularÄ±nÄ± YARATÄ°CÄ° ve KAPSAMLI ÅŸekilde yanÄ±tlamak
- Åirket bilgilerini kullanarak ÃœRETÄ°CÄ° Ã§Ã¶zÃ¼mler Ã¶nermek
- Ã–nceki konuÅŸma geÃ§miÅŸini dikkate alarak TUTARLI cevaplar vermek
- Her zaman nazik, yardÄ±mcÄ± ve profesyonel olmak

YAKLAÅIMIN:
1. Åirket bilgilerini temel al ama sadece kopyalama
2. Bilgileri analiz edip YARATICI Ã¶neriler sun
3. Ã‡alÄ±ÅŸanÄ±n Ã¶zel durumuna gÃ¶re KÄ°ÅÄ°SELLEÅTÄ°R
4. Eksik bilgi varsa mantÄ±klÄ± Ã‡IKARSAMALAR yap
5. Ã–nceki mesajlarla BAÄLANTI kur

Ã–NEMLÄ°: Bilgi yoksa: "${fallback}"

ÅÄ°RKET BÄ°LGÄ°LERÄ°:
${context}

LÃ¼tfen DETAYLI, YARATICI ve FAYDALI cevaplar ver. TÃ¼rkÃ§e yanÄ±t ver.`;

    // Chat history'yi messages'a dÃ¶nÃ¼ÅŸtÃ¼r
    const messages = [
      { role: 'system', content: systemPrompt }
    ];
    
    // Ã–nceki konuÅŸmalarÄ± ekle (son 6 mesaj - memory limit)
    const recentHistory = chatHistory.slice(-6);
    messages.push(...recentHistory);
    
    // Son kullanÄ±cÄ± mesajÄ±nÄ± ekle
    messages.push({ role: 'user', content: userQuery });

    console.log(`ğŸ§  ${messages.length} mesajlÄ± chat history ile yanÄ±t Ã¼retiliyor...`);
    
    return await this.createChatCompletion(messages, 0.3); // Biraz daha yaratÄ±cÄ±
  }

  /**
   * ANTI-REPETITION Chat Completion - Dynamic prompting for diverse responses
   */
  async antiRepetitionChatCompletion(userQuery, context = '', chatHistory = [], dynamicPrompt = '', options = {}) {
    const fallback = `${require('../config').support.fallbackMessage}`;
    
    // Dynamic prompt kullan, yoksa default'a geri dÃ¶n
    let systemPrompt = dynamicPrompt;
    
    if (!systemPrompt || systemPrompt.trim().length === 0) {
      systemPrompt = `Sen yaratÄ±cÄ± ve akÄ±llÄ± bir HR asistanÄ±sÄ±n. FarklÄ± perspektiflerden yanÄ±tlar ver.`;
    }
    
    // Context'i prompt'a ekle
    systemPrompt += `\n\nÅÄ°RKET BÄ°LGÄ°LERÄ°:\n${context}\n\nÃ–NEMLÄ°: Bilgi yoksa: "${fallback}"\n\nTÃ¼rkÃ§e yanÄ±t ver.`;
    
    // Messages array oluÅŸtur
    const messages = [
      { role: 'system', content: systemPrompt }
    ];
    
    // Chat history ekle (son 6 mesaj)
    if (chatHistory && chatHistory.length > 0) {
      const recentHistory = chatHistory.slice(-6);
      messages.push(...recentHistory);
    }
    
    // Current query ekle
    messages.push({ role: 'user', content: userQuery });
    
    console.log(`ğŸ”’ Anti-repetition chat completion: ${messages.length} mesaj, strategy=${options.strategy || 'normal'}`);
    
    // Temperature'Ä± dynamic olarak ayarla
    let temperature = options.temperature || 0.3;
    if (options.strategy === 'aggressive_diversification') {
      temperature = 0.8; // Daha yaratÄ±cÄ±
    } else if (options.strategy === 'moderate_diversification') {
      temperature = 0.5; // Orta seviye yaratÄ±cÄ±lÄ±k
    }
    
    return await this.createChatCompletion(messages, temperature);
  }

  /**
   * Ollama servisinin saÄŸlÄ±ÄŸÄ±nÄ± kontrol et
   */
  async checkHealth() {
    try {
      const response = await this.client.get('/api/tags');
      
      // Model listesinde bizim modelimiz var mÄ± kontrol et
      if (response.data && response.data.models) {
        const models = response.data.models.map(m => m.name);
        if (models.includes(this.model)) {
          console.log(`âœ… Ollama servisi Ã§alÄ±ÅŸÄ±yor, model "${this.model}" yÃ¼klÃ¼`);
          return true;
        } else {
          console.warn(`âš ï¸  Model "${this.model}" Ollama'da bulunamadÄ±. YÃ¼klÃ¼ modeller:`, models);
          return false;
        }
      }
      
      console.log('âœ… Ollama servisi Ã§alÄ±ÅŸÄ±yor');
      return true;
    } catch (error) {
      console.error('âŒ Ollama servisi Ã§alÄ±ÅŸmÄ±yor:', error.message);
      console.log('ğŸ’¡ Ollama\'yÄ± baÅŸlatmak iÃ§in: ollama serve');
      console.log(`ğŸ’¡ Model indirmek iÃ§in: ollama pull ${this.model}`);
      return false;
    }
  }
}

module.exports = OllamaClient;
