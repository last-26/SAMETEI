#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GeliÅŸtirilmiÅŸ OCR - Qwen Modeli ile GÃ¶rÃ¼ntÃ¼den Metin Ã‡Ä±karma
KullanÄ±m: python improved_ocr.py <gÃ¶rÃ¼ntÃ¼_dosyasÄ±>
"""

import os
import sys
import io
import base64
import logging
from PIL import Image, ImageEnhance, ImageOps
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info
import torch
import numpy as np

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_model():
    """Qwen modelini yÃ¼kle"""
    global model, processor, device

    try:
        # GPU kontrolÃ¼
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"KullanÄ±lacak cihaz: {device}")

        # Model ID
        model_id = "Qwen/Qwen2.5-VL-3B-Instruct"

        # Processor yÃ¼kle - daha yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼k limitleri
        processor = AutoProcessor.from_pretrained(
            model_id,
            trust_remote_code=True,
            min_pixels=1024 * 28 * 28,  # Min piksel artÄ±rÄ±ldÄ±
            max_pixels=2048 * 28 * 28,  # Max piksel artÄ±rÄ±ldÄ±
        )

        # Model yÃ¼kle
        model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            device_map="auto" if torch.cuda.is_available() else "cpu",
            trust_remote_code=True,
            low_cpu_mem_usage=True,
        )

        model.eval()
        logger.info("âœ… Model baÅŸarÄ±yla yÃ¼klendi!")
        return True

    except Exception as e:
        logger.error(f"âŒ Model yÃ¼kleme hatasÄ±: {e}")
        return False

def enhance_image(image):
    """GÃ¶rÃ¼ntÃ¼ kalitesini artÄ±r"""
    try:
        # Contrast artÄ±rma
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.5)
        
        # Brightness ayarlama
        enhancer = ImageEnhance.Brightness(image)
        image = enhancer.enhance(1.2)
        
        # Sharpness artÄ±rma
        enhancer = ImageEnhance.Sharpness(image)
        image = enhancer.enhance(2.0)
        
        return image
    except Exception as e:
        logger.warning(f"GÃ¶rÃ¼ntÃ¼ iyileÅŸtirme uyarÄ±sÄ±: {e}")
        return image

def detect_and_correct_rotation(image):
    """GÃ¶rÃ¼ntÃ¼ rotasyonunu tespit et ve dÃ¼zelt"""
    try:
        # PIL'in EXIF bilgilerini kullanarak otomatik dÃ¶ndÃ¼rme
        image = ImageOps.exif_transpose(image)
        
        # Ek olarak, gÃ¶rÃ¼ntÃ¼yÃ¼ numpy array'e Ã§evir
        img_array = np.array(image)
        
        # Basit bir kenar tespiti ile metin yÃ¶nÃ¼nÃ¼ kontrol et
        # (Bu kÄ±sÄ±m opsiyonel, gerekirse daha geliÅŸmiÅŸ algoritmalar kullanÄ±labilir)
        
        return image
    except Exception as e:
        logger.warning(f"Rotasyon dÃ¼zeltme uyarÄ±sÄ±: {e}")
        return image

def preprocess_image(image_path):
    """GÃ¶rÃ¼ntÃ¼yÃ¼ geliÅŸmiÅŸ Ã¶n iÅŸleme"""
    try:
        # GÃ¶rÃ¼ntÃ¼yÃ¼ aÃ§
        image = Image.open(image_path)
        
        # RGB'ye Ã§evir
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # Rotasyonu dÃ¼zelt
        image = detect_and_correct_rotation(image)
        
        # GÃ¶rÃ¼ntÃ¼ kalitesini artÄ±r
        image = enhance_image(image)
        
        # GÃ¶rÃ¼ntÃ¼ boyutunu kontrol et ve gerekirse resize et
        width, height = image.size
        max_dimension = 3000  # Maksimum boyut
        
        if width > max_dimension or height > max_dimension:
            ratio = min(max_dimension/width, max_dimension/height)
            new_width = int(width * ratio)
            new_height = int(height * ratio)
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            logger.info(f"ğŸ“ GÃ¶rÃ¼ntÃ¼ yeniden boyutlandÄ±rÄ±ldÄ±: {new_width}x{new_height}")
        
        logger.info(f"ğŸ“· GÃ¶rÃ¼ntÃ¼ iÅŸlendi: {image.size}")
        return image

    except Exception as e:
        logger.error(f"âŒ GÃ¶rÃ¼ntÃ¼ yÃ¼kleme hatasÄ±: {e}")
        return None

def image_to_base64(image):
    """GÃ¶rÃ¼ntÃ¼yÃ¼ base64'e Ã§evir"""
    try:
        # Buffer'a kaydet
        buffer = io.BytesIO()
        image.save(buffer, format='JPEG', quality=95)  # Kaliteyi artÄ±r
        buffer.seek(0)

        # Base64'e Ã§evir
        image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
        return image_base64

    except Exception as e:
        logger.error(f"âŒ Base64 Ã§evirme hatasÄ±: {e}")
        return None

def extract_text_from_image(image):
    """GÃ¶rÃ¼ntÃ¼den metin Ã§Ä±kar - geliÅŸtirilmiÅŸ yaklaÅŸÄ±m"""
    try:
        # Base64'e Ã§evir
        image_base64 = image_to_base64(image)
        if not image_base64:
            return None

        # GeliÅŸtirilmiÅŸ prompt - daha spesifik talimatlar
        prompt = """Bu gÃ¶rÃ¼ntÃ¼deki TÃœM metinleri Ã§Ä±kar. 
        
        KURALLAR:
        1. Her metin parÃ§asÄ±nÄ± ORIJINAL KONUMUNA ve SIRASINA gÃ¶re Ã§Ä±kar
        2. Tablo varsa, satÄ±r ve sÃ¼tun yapÄ±sÄ±nÄ± koru
        3. TÃ¼rkÃ§e karakterleri (Ã§, ÄŸ, Ä±, Ã¶, ÅŸ, Ã¼) tam olarak koru
        4. Renkli arka planlardaki metinleri de oku
        5. Dikey veya yatay tÃ¼m metinleri oku
        6. HÄ°Ã‡BÄ°R metni atlama, tekrarlama veya deÄŸiÅŸtirme
        7. Form yapÄ±sÄ±nÄ± ve dÃ¼zenini koru
        8. BoÅŸ hÃ¼creleri veya alanlarÄ± da belirt
        
        Ã‡IKTI FORMATI:
        - Tablolar iÃ§in satÄ±r sonlarÄ±nda \n kullan, sÃ¼tunlarÄ± \t ile ayÄ±r.
        - Formlar iÃ§in alan adÄ±: deÄŸer formatÄ±nÄ± kullan
        - Her bÃ¶lÃ¼mÃ¼ ayrÄ± satÄ±rlarda gÃ¶ster
        
        Åimdi gÃ¶rÃ¼ntÃ¼deki TÃœM metinleri tam olarak Ã§Ä±kar:"""

        # MesajlarÄ± hazÄ±rla
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image", "image": image},
                ],
            }
        ]

        # Model ile Ã§Ä±karÄ±m
        logger.info("ğŸ” OCR iÅŸlemi baÅŸlatÄ±lÄ±yor...")

        # Chat template uygula
        prompt_text = processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )

        # GÃ¶rsel giriÅŸleri iÅŸle
        image_inputs, video_inputs = process_vision_info(messages)

        # TensorlarÄ± hazÄ±rla
        inputs = processor(
            text=[prompt_text],
            images=image_inputs,
            videos=video_inputs,
            padding=True,
            return_tensors="pt",
        ).to(device)

        # Model Ã§Ä±karÄ±mÄ± - artÄ±rÄ±lmÄ±ÅŸ token limiti
        with torch.no_grad():
            generated_ids = model.generate(
                **inputs,
                max_new_tokens=4096,  # Token limiti 4 katÄ±na Ã§Ä±karÄ±ldÄ±
                temperature=0.0,      # Deterministik
                do_sample=False,
                num_beams=3,          # Beam search ile daha iyi sonuÃ§lar
                repetition_penalty=1.2,  # TekrarlarÄ± Ã¶nle
                eos_token_id=getattr(processor.tokenizer, 'eos_token_id', None),
                pad_token_id=getattr(processor.tokenizer, 'pad_token_id', None),
            )

        # Ã‡Ä±ktÄ±yÄ± decode et
        generated_ids_trimmed = [
            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]

        output_text = processor.batch_decode(
            generated_ids_trimmed,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False
        )[0]

        logger.info("âœ… OCR tamamlandÄ±!")
        return output_text.strip()

    except Exception as e:
        logger.error(f"âŒ OCR hatasÄ±: {e}")
        return None

def post_process_text(text):
    """OCR sonucunu post-processing ile iyileÅŸtir"""
    if not text:
        return ""
    
    import re
    
    # Gereksiz baÅŸlangÄ±Ã§ metinlerini temizle
    text = re.sub(r"^.*?Ã§Ä±kar[Ä±i]lan.*?:\s*", "", text, flags=re.IGNORECASE | re.DOTALL)
    text = re.sub(r"^.*?metin.*?:\s*", "", text, flags=re.IGNORECASE | re.DOTALL)
    
    # Code block'lardan Ã§Ä±kar
    fence = re.compile(r"```[a-zA-Z0-9]*\n([\s\S]*?)\n```")
    match = fence.search(text)
    if match:
        text = match.group(1).strip()
    
    # Tekrarlanan satÄ±rlarÄ± tespit et ve kaldÄ±r
    lines = text.split('\n')
    unique_lines = []
    prev_line = None
    
    for line in lines:
        # BoÅŸ satÄ±rlarÄ± koru ama tekrarlarÄ± Ã¶nle
        if line.strip() != prev_line:
            unique_lines.append(line)
            prev_line = line.strip() if line.strip() else prev_line
    
    text = '\n'.join(unique_lines)
    
    # Fazla boÅŸluklarÄ± dÃ¼zenle
    text = re.sub(r"[ \t]+", " ", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    
    return text.strip()

def process_in_segments(image, segment_size=500):
    """BÃ¼yÃ¼k gÃ¶rÃ¼ntÃ¼leri segmentlere ayÄ±rarak iÅŸle"""
    width, height = image.size
    results = []
    
    if height > segment_size * 2:  # EÄŸer gÃ¶rÃ¼ntÃ¼ Ã§ok uzunsa
        logger.info("ğŸ“‹ GÃ¶rÃ¼ntÃ¼ segmentlere ayrÄ±lÄ±yor...")
        
        for y in range(0, height, segment_size):
            # Segment oluÅŸtur (biraz overlap ekle)
            overlap = 50  # Piksel cinsinden overlap
            y_start = max(0, y - overlap)
            y_end = min(height, y + segment_size + overlap)
            
            # Segmenti kes
            segment = image.crop((0, y_start, width, y_end))
            
            # Her segmenti OCR'la
            segment_text = extract_text_from_image(segment)
            if segment_text:
                results.append(segment_text)
        
        return "\n".join(results)
    else:
        # Normal iÅŸlem
        return extract_text_from_image(image)

def main():
    """Ana fonksiyon"""
    try:
        if len(sys.argv) < 2:
            print("KullanÄ±m: python improved_ocr.py <gÃ¶rÃ¼ntÃ¼_dosyasÄ±>")
            print("Ã–rnek: python improved_ocr.py test.png")
            return

        image_name = sys.argv[1]
        image_path = os.path.join("temp", image_name)

        if not os.path.exists(image_path):
            print(f"âŒ Dosya bulunamadÄ±: {image_path}")
            return

        print("ğŸš€ GeliÅŸtirilmiÅŸ OCR baÅŸlatÄ±lÄ±yor...")
        print(f"ğŸ“ GÃ¶rÃ¼ntÃ¼: {image_path}")

        # Model yÃ¼kle
        if not load_model():
            print("âŒ Model yÃ¼klenemedi!")
            return

        # GÃ¶rÃ¼ntÃ¼yÃ¼ iÅŸle
        image = preprocess_image(image_path)
        if not image:
            print("âŒ GÃ¶rÃ¼ntÃ¼ yÃ¼klenemedi!")
            return

        # OCR Ã§Ä±karÄ±m - bÃ¼yÃ¼k gÃ¶rÃ¼ntÃ¼ler iÃ§in segment bazlÄ±
        width, height = image.size
        if height > 2000:  # Uzun gÃ¶rÃ¼ntÃ¼ler iÃ§in
            raw_text = process_in_segments(image)
        else:
            raw_text = extract_text_from_image(image)
        
        if not raw_text:
            print("âŒ OCR baÅŸarÄ±sÄ±z!")
            return

        # Post-processing
        clean_text = post_process_text(raw_text)

        # Sonucu gÃ¶ster
        print("\n" + "="*50)
        print("ğŸ“ Ã‡IKARILAN METÄ°N:")
        print("="*50)
        print(clean_text)
        print("="*50)
        print(f"ğŸ“Š Karakter sayÄ±sÄ±: {len(clean_text)}")

        # Dosyaya kaydet
        output_file = os.path.splitext(image_path)[0] + "_ocr_improved.txt"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(clean_text)

        print(f"ğŸ’¾ SonuÃ§ kaydedildi: {output_file}")

    except KeyboardInterrupt:
        print("\nâ¹ Ä°ÅŸlem kullanÄ±cÄ± tarafÄ±ndan durduruldu")
    except Exception as e:
        print(f"âŒ Beklenmeyen hata: {e}")

if __name__ == "__main__":
    main()